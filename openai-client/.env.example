# OpenAI Client Configuration
# This version uses OpenAIClient instead of AzureAIClient (no Foundry project needed)

# ============================================
# OPTION 1: Direct OpenAI API
# ============================================
# OPENAI_API_KEY=sk-...

# ============================================
# OPTION 2: Azure OpenAI (without Foundry)
# ============================================
# AZURE_OPENAI_API_KEY=your-azure-openai-api-key
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com

# Model deployment name (e.g., gpt-4o, gpt-4o-mini, gpt-35-turbo)
AZURE_AI_MODEL_DEPLOYMENT_NAME=gpt-4o

# Todo API URL - JSONPlaceholder API for todo data
TODO_API_URL=https://jsonplaceholder.typicode.com/todos

# Optional: Port for this service (default: 8080)
PORT=8080

# ============================================
# TRACING (REQUIRED for Application Insights)
# ============================================
# Since we're NOT using a Foundry project, APPLICATIONINSIGHTS_CONNECTION_STRING
# is REQUIRED to export traces to Application Insights.
#
# Get this from Azure Portal -> Application Insights -> Properties
APPLICATIONINSIGHTS_CONNECTION_STRING=InstrumentationKey=...;IngestionEndpoint=...

# Optional: Service name for OpenTelemetry tracing (default: todo-agent)
OTEL_SERVICE_NAME=todo-agent

# Optional: Agent ID for tracing (appears as gen_ai.agent.id in customDimensions)
AGENT_ID=TodoAgent

# Optional: Enable sensitive data recording in traces (default: true)
# ENABLE_SENSITIVE_DATA=true
